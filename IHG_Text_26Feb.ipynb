{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JyBzJwBYUNK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6ChVoSbYyfE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\u326421\\Desktop\\IHG - Text\\gcp_op1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RR4ov98xax5z",
    "outputId": "8c9dbde1-6408-447b-abeb-481728a84e67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_SID', 'Text', 'level_2', 'ent_op', 'entity', 'type', 'salience'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df[\"Text\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OD0Es1xQbvEe"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: re.sub('[^.,a-zA-Z0-9 \\n\\.]', '',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsRR2NUibviM"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "DfYNCh-Fb93U",
    "outputId": "5d9df002-4cf2-4ebd-fa90-825b7825513d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_SID</th>\n",
       "      <th>Text</th>\n",
       "      <th>level_2</th>\n",
       "      <th>ent_op</th>\n",
       "      <th>entity</th>\n",
       "      <th>type</th>\n",
       "      <th>salience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>0</td>\n",
       "      <td>('clinic', 'LOCATION', 0.5232729315757751)</td>\n",
       "      <td>clinic</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.523273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>1</td>\n",
       "      <td>('shuttle', 'OTHER', 0.47672703862190247)</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.476727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17504_1000_Q2_1</td>\n",
       "      <td>i booked a handicapped room</td>\n",
       "      <td>0</td>\n",
       "      <td>('room', 'LOCATION', 1.0)</td>\n",
       "      <td>room</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17504_1000_Q2_10</td>\n",
       "      <td>came back home because we couldnt afford ano...</td>\n",
       "      <td>0</td>\n",
       "      <td>('home', 'LOCATION', 1.0)</td>\n",
       "      <td>home</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17504_1000_Q2_11</td>\n",
       "      <td>was told i should call the day before so the...</td>\n",
       "      <td>0</td>\n",
       "      <td>('room', 'LOCATION', 0.8343371152877808)</td>\n",
       "      <td>room</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.834337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_SID                                               Text  \\\n",
       "0   17504_1000_Q1_1              close to clinic and could get shuttle   \n",
       "1   17504_1000_Q1_1              close to clinic and could get shuttle   \n",
       "2   17504_1000_Q2_1                        i booked a handicapped room   \n",
       "3  17504_1000_Q2_10    came back home because we couldnt afford ano...   \n",
       "4  17504_1000_Q2_11    was told i should call the day before so the...   \n",
       "\n",
       "   level_2                                      ent_op   entity      type  \\\n",
       "0        0  ('clinic', 'LOCATION', 0.5232729315757751)   clinic  LOCATION   \n",
       "1        1   ('shuttle', 'OTHER', 0.47672703862190247)  shuttle     OTHER   \n",
       "2        0                   ('room', 'LOCATION', 1.0)     room  LOCATION   \n",
       "3        0                   ('home', 'LOCATION', 1.0)     home  LOCATION   \n",
       "4        0    ('room', 'LOCATION', 0.8343371152877808)     room  LOCATION   \n",
       "\n",
       "   salience  \n",
       "0  0.523273  \n",
       "1  0.476727  \n",
       "2  1.000000  \n",
       "3  1.000000  \n",
       "4  0.834337  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD2BgtUHLMxN"
   },
   "outputs": [],
   "source": [
    "# df2  = df.set_index('Unique_ID').Text.str.split(\".\").apply(pd.Series).stack().reset_index(name = 'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ghvIwqOQLNAh",
    "outputId": "2c576b46-c982-47f6-9de9-d31ae9e2a03c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentence_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301_1_Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>2301_1_Q1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2301_1_Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>2301_1_Q1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301_2_Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>2301_2_Q1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2301_2_Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>i work across the lot from a marriott and the...</td>\n",
       "      <td>2301_2_Q1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2301_3_Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>clean and very friendly staff</td>\n",
       "      <td>2301_3_Q1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID  level_1                                               Text  \\\n",
       "0  2301_1_Q1        0           location and friendly professional staff   \n",
       "1  2301_1_Q1        1                           valet service was a plus   \n",
       "2  2301_2_Q1        0  it was great the only thing that slightly bugg...   \n",
       "3  2301_2_Q1        1   i work across the lot from a marriott and the...   \n",
       "4  2301_3_Q1        0                      clean and very friendly staff   \n",
       "\n",
       "   Sentence_ID  \n",
       "0  2301_1_Q1_1  \n",
       "1  2301_1_Q1_2  \n",
       "2  2301_2_Q1_1  \n",
       "3  2301_2_Q1_2  \n",
       "4  2301_3_Q1_1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2['Sentence_ID'] = df.set_index('Unique_ID').Text.str.split(\".\").apply(pd.Series).stack().reset_index(name = 'Text').\\\n",
    "# apply(lambda x : str(x['Unique_ID']) + \"_\" + str(x['level_1'] + 1), axis = 1)\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zfEN28xLNNR"
   },
   "outputs": [],
   "source": [
    "# df2 = df2.drop([\"Unique_ID\" , \"level_1\"],  axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10550, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['derek', 'anderson']"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordninja.split('derekanderson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ninjasplit(x):\n",
    "#     l1 =[]\n",
    "#     for str in x:\n",
    "#         l1.append(wordninja.split(x))\n",
    "#     return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['wn_sent'] = df2.Text.apply(lambda x: \" \".join(wordninja.split(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKgU5OgQi8HQ"
   },
   "source": [
    "### **GETTING ENTITIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "VdJlwPilam21",
    "outputId": "35259908-eb19-4e8a-dd63-cb8d887f31ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\u326421\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\u326421\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\u326421\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28kDcXSEarIS"
   },
   "outputs": [],
   "source": [
    "#Finding nouns to get entities\n",
    "df2['nouns'] = df2.Text.apply(lambda x : [a for a,b in TextBlob(x).pos_tags if b in ['NN','NNS', 'NNP', 'NNPS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wc_xhK9zcwmX"
   },
   "outputs": [],
   "source": [
    "df2['nouns'] = df2['nouns'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "Knn82LSUNkKL",
    "outputId": "e8d763a5-0963-4ee9-940a-a93c069cde23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_SID</th>\n",
       "      <th>Text</th>\n",
       "      <th>level_2</th>\n",
       "      <th>ent_op</th>\n",
       "      <th>entity</th>\n",
       "      <th>type</th>\n",
       "      <th>salience</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>0</td>\n",
       "      <td>('clinic', 'LOCATION', 0.5232729315757751)</td>\n",
       "      <td>clinic</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.523273</td>\n",
       "      <td>clinic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>1</td>\n",
       "      <td>('shuttle', 'OTHER', 0.47672703862190247)</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.476727</td>\n",
       "      <td>clinic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_SID                                   Text  level_2  \\\n",
       "0  17504_1000_Q1_1  close to clinic and could get shuttle        0   \n",
       "1  17504_1000_Q1_1  close to clinic and could get shuttle        1   \n",
       "\n",
       "                                       ent_op   entity      type  salience  \\\n",
       "0  ('clinic', 'LOCATION', 0.5232729315757751)   clinic  LOCATION  0.523273   \n",
       "1   ('shuttle', 'OTHER', 0.47672703862190247)  shuttle     OTHER  0.476727   \n",
       "\n",
       "    nouns  \n",
       "0  clinic  \n",
       "1  clinic  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making sure each row has only one entity\n",
    "df1  = df2.set_index('ID_SID').nouns.str.split(\",\").apply(pd.Series).stack().reset_index(name = 'nouns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_SID</th>\n",
       "      <th>level_1</th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17504_1000_Q2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>17504_1000_Q2_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17504_1000_Q2_1</td>\n",
       "      <td>1</td>\n",
       "      <td>room</td>\n",
       "      <td>17504_1000_Q2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17504_1000_Q2_10</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>17504_1000_Q2_10_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_SID  level_1   nouns                  ID\n",
       "0   17504_1000_Q1_1        0  clinic   17504_1000_Q1_1_1\n",
       "1   17504_1000_Q1_1        0  clinic   17504_1000_Q1_1_1\n",
       "2   17504_1000_Q2_1        0       i   17504_1000_Q2_1_1\n",
       "3   17504_1000_Q2_1        1    room   17504_1000_Q2_1_2\n",
       "4  17504_1000_Q2_10        0    home  17504_1000_Q2_10_1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Making sure each row has only one entity\n",
    "df1['ID'] = df2.set_index('ID_SID').nouns.str.split(\",\").apply(pd.Series).stack().reset_index(name = 'nouns').\\\n",
    "apply(lambda x : str(x['ID_SID']) + \"_\" + str(x['level_1'] + 1), axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop([\"level_1\"],  axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(df1, df2, on='ID_SID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['nouns_y'],  axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={\"nouns_x\": \"nouns\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_SID</th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>level_2</th>\n",
       "      <th>ent_op</th>\n",
       "      <th>entity</th>\n",
       "      <th>type</th>\n",
       "      <th>salience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>0</td>\n",
       "      <td>('clinic', 'LOCATION', 0.5232729315757751)</td>\n",
       "      <td>clinic</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.523273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>1</td>\n",
       "      <td>('shuttle', 'OTHER', 0.47672703862190247)</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.476727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>0</td>\n",
       "      <td>('clinic', 'LOCATION', 0.5232729315757751)</td>\n",
       "      <td>clinic</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.523273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>1</td>\n",
       "      <td>('shuttle', 'OTHER', 0.47672703862190247)</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.476727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17504_1000_Q2_1</td>\n",
       "      <td>i</td>\n",
       "      <td>17504_1000_Q2_1_1</td>\n",
       "      <td>i booked a handicapped room</td>\n",
       "      <td>0</td>\n",
       "      <td>('room', 'LOCATION', 1.0)</td>\n",
       "      <td>room</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518315</th>\n",
       "      <td>2301_9_Q1_1</td>\n",
       "      <td>staff</td>\n",
       "      <td>2301_9_Q1_1_2</td>\n",
       "      <td>politeness of staff</td>\n",
       "      <td>1</td>\n",
       "      <td>('staff', 'PERSON', 0.11625086516141891)</td>\n",
       "      <td>staff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.116251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518316</th>\n",
       "      <td>2301_9_Q1_1</td>\n",
       "      <td>politeness</td>\n",
       "      <td>2301_9_Q1_1_1</td>\n",
       "      <td>politeness of staff</td>\n",
       "      <td>0</td>\n",
       "      <td>('politeness', 'OTHER', 0.8837491273880005)</td>\n",
       "      <td>politeness</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.883749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518317</th>\n",
       "      <td>2301_9_Q1_1</td>\n",
       "      <td>politeness</td>\n",
       "      <td>2301_9_Q1_1_1</td>\n",
       "      <td>politeness of staff</td>\n",
       "      <td>1</td>\n",
       "      <td>('staff', 'PERSON', 0.11625086516141891)</td>\n",
       "      <td>staff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.116251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518318</th>\n",
       "      <td>2301_9_Q1_1</td>\n",
       "      <td>staff</td>\n",
       "      <td>2301_9_Q1_1_2</td>\n",
       "      <td>politeness of staff</td>\n",
       "      <td>0</td>\n",
       "      <td>('politeness', 'OTHER', 0.8837491273880005)</td>\n",
       "      <td>politeness</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.883749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518319</th>\n",
       "      <td>2301_9_Q1_1</td>\n",
       "      <td>staff</td>\n",
       "      <td>2301_9_Q1_1_2</td>\n",
       "      <td>politeness of staff</td>\n",
       "      <td>1</td>\n",
       "      <td>('staff', 'PERSON', 0.11625086516141891)</td>\n",
       "      <td>staff</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.116251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID_SID       nouns                 ID  \\\n",
       "0       17504_1000_Q1_1      clinic  17504_1000_Q1_1_1   \n",
       "1       17504_1000_Q1_1      clinic  17504_1000_Q1_1_1   \n",
       "2       17504_1000_Q1_1      clinic  17504_1000_Q1_1_1   \n",
       "3       17504_1000_Q1_1      clinic  17504_1000_Q1_1_1   \n",
       "4       17504_1000_Q2_1           i  17504_1000_Q2_1_1   \n",
       "...                 ...         ...                ...   \n",
       "518315      2301_9_Q1_1       staff      2301_9_Q1_1_2   \n",
       "518316      2301_9_Q1_1  politeness      2301_9_Q1_1_1   \n",
       "518317      2301_9_Q1_1  politeness      2301_9_Q1_1_1   \n",
       "518318      2301_9_Q1_1       staff      2301_9_Q1_1_2   \n",
       "518319      2301_9_Q1_1       staff      2301_9_Q1_1_2   \n",
       "\n",
       "                                         Text  level_2  \\\n",
       "0       close to clinic and could get shuttle        0   \n",
       "1       close to clinic and could get shuttle        1   \n",
       "2       close to clinic and could get shuttle        0   \n",
       "3       close to clinic and could get shuttle        1   \n",
       "4                 i booked a handicapped room        0   \n",
       "...                                       ...      ...   \n",
       "518315                    politeness of staff        1   \n",
       "518316                    politeness of staff        0   \n",
       "518317                    politeness of staff        1   \n",
       "518318                    politeness of staff        0   \n",
       "518319                    politeness of staff        1   \n",
       "\n",
       "                                             ent_op      entity      type  \\\n",
       "0        ('clinic', 'LOCATION', 0.5232729315757751)      clinic  LOCATION   \n",
       "1         ('shuttle', 'OTHER', 0.47672703862190247)     shuttle     OTHER   \n",
       "2        ('clinic', 'LOCATION', 0.5232729315757751)      clinic  LOCATION   \n",
       "3         ('shuttle', 'OTHER', 0.47672703862190247)     shuttle     OTHER   \n",
       "4                         ('room', 'LOCATION', 1.0)        room  LOCATION   \n",
       "...                                             ...         ...       ...   \n",
       "518315     ('staff', 'PERSON', 0.11625086516141891)       staff    PERSON   \n",
       "518316  ('politeness', 'OTHER', 0.8837491273880005)  politeness     OTHER   \n",
       "518317     ('staff', 'PERSON', 0.11625086516141891)       staff    PERSON   \n",
       "518318  ('politeness', 'OTHER', 0.8837491273880005)  politeness     OTHER   \n",
       "518319     ('staff', 'PERSON', 0.11625086516141891)       staff    PERSON   \n",
       "\n",
       "        salience  \n",
       "0       0.523273  \n",
       "1       0.476727  \n",
       "2       0.523273  \n",
       "3       0.476727  \n",
       "4       1.000000  \n",
       "...          ...  \n",
       "518315  0.116251  \n",
       "518316  0.883749  \n",
       "518317  0.116251  \n",
       "518318  0.883749  \n",
       "518319  0.116251  \n",
       "\n",
       "[518320 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enttags(text):\n",
    "#     doc = nlp(text)\n",
    "#     l1 =[]\n",
    "#     for ent in doc.ents:\n",
    "#         l1.append((ent.text,ent.label_))\n",
    "#     return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enttags(\"Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[\"Spacy_Entity\"] = df1.Text.map(str).apply(lambda x: enttags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.Spacy_Entity.apply(lambda x: x.replace(\"[\",\"\")).\\\n",
    "# apply(lambda x: x.replace(\"]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_SID</th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>level_2</th>\n",
       "      <th>ent_op</th>\n",
       "      <th>entity</th>\n",
       "      <th>type</th>\n",
       "      <th>salience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>0</td>\n",
       "      <td>('clinic', 'LOCATION', 0.5232729315757751)</td>\n",
       "      <td>clinic</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.523273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>1</td>\n",
       "      <td>('shuttle', 'OTHER', 0.47672703862190247)</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.476727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>0</td>\n",
       "      <td>('clinic', 'LOCATION', 0.5232729315757751)</td>\n",
       "      <td>clinic</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>0.523273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17504_1000_Q1_1</td>\n",
       "      <td>clinic</td>\n",
       "      <td>17504_1000_Q1_1_1</td>\n",
       "      <td>close to clinic and could get shuttle</td>\n",
       "      <td>1</td>\n",
       "      <td>('shuttle', 'OTHER', 0.47672703862190247)</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.476727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17504_1000_Q2_1</td>\n",
       "      <td>i</td>\n",
       "      <td>17504_1000_Q2_1_1</td>\n",
       "      <td>i booked a handicapped room</td>\n",
       "      <td>0</td>\n",
       "      <td>('room', 'LOCATION', 1.0)</td>\n",
       "      <td>room</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_SID   nouns                 ID  \\\n",
       "0  17504_1000_Q1_1  clinic  17504_1000_Q1_1_1   \n",
       "1  17504_1000_Q1_1  clinic  17504_1000_Q1_1_1   \n",
       "2  17504_1000_Q1_1  clinic  17504_1000_Q1_1_1   \n",
       "3  17504_1000_Q1_1  clinic  17504_1000_Q1_1_1   \n",
       "4  17504_1000_Q2_1       i  17504_1000_Q2_1_1   \n",
       "\n",
       "                                    Text  level_2  \\\n",
       "0  close to clinic and could get shuttle        0   \n",
       "1  close to clinic and could get shuttle        1   \n",
       "2  close to clinic and could get shuttle        0   \n",
       "3  close to clinic and could get shuttle        1   \n",
       "4            i booked a handicapped room        0   \n",
       "\n",
       "                                       ent_op   entity      type  salience  \n",
       "0  ('clinic', 'LOCATION', 0.5232729315757751)   clinic  LOCATION  0.523273  \n",
       "1   ('shuttle', 'OTHER', 0.47672703862190247)  shuttle     OTHER  0.476727  \n",
       "2  ('clinic', 'LOCATION', 0.5232729315757751)   clinic  LOCATION  0.523273  \n",
       "3   ('shuttle', 'OTHER', 0.47672703862190247)  shuttle     OTHER  0.476727  \n",
       "4                   ('room', 'LOCATION', 1.0)     room  LOCATION  1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIu92_m1ggAk"
   },
   "source": [
    "### **GETTING DESCRIPTORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hHNhHJ4cW6h"
   },
   "outputs": [],
   "source": [
    "#Finding adjectives for descriptors\n",
    "df1['textblob_adjtags'] = df1.Text.apply(lambda x : [a for a,b in TextBlob(x).pos_tags if b in ['JJ','JJR','JJS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87DImuIjdZ4_"
   },
   "outputs": [],
   "source": [
    "df1['textblob_adjtags'] = df1['textblob_adjtags'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NDuL5ggdhIp"
   },
   "outputs": [],
   "source": [
    "#Finding adverbs for descriptors\n",
    "df1['textblob_advtags'] = df1.Text.apply(lambda x : [a for a,b in TextBlob(x).pos_tags if b in ['RB','RBR','RBS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6NqVzyeH-p"
   },
   "outputs": [],
   "source": [
    "df1['textblob_advtags'] = df1['textblob_advtags'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "h3Y-dkyyeT22",
    "outputId": "be73819f-5aaf-4391-b2ca-159788425f93"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebyIP2tpfyOe"
   },
   "outputs": [],
   "source": [
    "#For descriptors\n",
    "#Function to remove stop words\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "def rem_stopwords(text):\n",
    "  my_doc = nlp(text)\n",
    "  # Create list of word tokens\n",
    "  token_list = []\n",
    "  for token in my_doc:\n",
    "      token_list.append(token.text)\n",
    "\n",
    "  from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "  # Create list of word tokens after removing stopwords\n",
    "  filtered_sentence =[] \n",
    "\n",
    "  for word in token_list:\n",
    "      lexeme = nlp.vocab[word]\n",
    "      if lexeme.is_stop == False:\n",
    "        filtered_sentence.append(word) \n",
    "\n",
    "  filtered_sentence = \" \".join(filtered_sentence)\n",
    "  return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "isZEDkoaf9nd",
    "outputId": "835082e3-d225-44f3-a293-2c4522d5d961"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valet</td>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service</td>\n",
       "      <td>2301_1_Q1_2_2</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plus</td>\n",
       "      <td>2301_1_Q1_2_3</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nouns             ID                                      Text  \\\n",
       "0  location  2301_1_Q1_1_1  location and friendly professional staff   \n",
       "1     staff  2301_1_Q1_1_2  location and friendly professional staff   \n",
       "2     valet  2301_1_Q1_2_1                  valet service was a plus   \n",
       "3   service  2301_1_Q1_2_2                  valet service was a plus   \n",
       "4      plus  2301_1_Q1_2_3                  valet service was a plus   \n",
       "\n",
       "                                    wn_sent Spacy_Entity  \\\n",
       "0  location and friendly professional staff           []   \n",
       "1  location and friendly professional staff           []   \n",
       "2                  valet service was a plus           []   \n",
       "3                  valet service was a plus           []   \n",
       "4                  valet service was a plus           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \n",
       "0  friendly,professional                   friendly,professional  \n",
       "1  friendly,professional                   friendly,professional  \n",
       "2                                                                 \n",
       "3                                                                 \n",
       "4                                                                 "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['adjtags_removedSW'] = df1.Text.apply(rem_stopwords).apply(lambda x : \",\".join([a for a,b in TextBlob(x).pos_tags if b in ['JJ','JJR','JJS']])) \n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qqQXlZfgeaJX",
    "outputId": "9e72fe7a-17e5-4872-9b71-c9c56c1ed50a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\u326421\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Function to get Stop words using NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "set(stopwords.words('english'))\n",
    "\n",
    "def rem_stopwords_stemming(text):\n",
    "  stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "  word_tokens = word_tokenize(text) \n",
    "  filtered_sentence = [] \n",
    "  \n",
    "  for w in word_tokens: \n",
    "      if w not in stop_words: \n",
    "          filtered_sentence.append(w) \n",
    "\n",
    "  Stem_words = []\n",
    "  ps =PorterStemmer()\n",
    "  for w in filtered_sentence:\n",
    "      rootWord=ps.stem(w)\n",
    "      Stem_words.append(rootWord)\n",
    "  Stem_words = \" \".join(Stem_words)\n",
    "\n",
    "  return Stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization using spacy - does not remove stop words\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def lemma_spacy(doc):\n",
    "  doc = nlp(doc)\n",
    "  lemma_word1 = [] \n",
    "  for token in doc:\n",
    "      lemma_word1.append(token.lemma_)\n",
    "  return \" \".join(lemma_word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAaFnDgne1Jm"
   },
   "outputs": [],
   "source": [
    "df1['adj_after_stemming'] = df1.Text.apply(rem_stopwords_stemming).apply(lambda x : \",\".join([a for a,b in TextBlob(x).pos_tags if b in ['JJ','JJR','JJS']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XehrCe8FfO_v"
   },
   "outputs": [],
   "source": [
    "df1['adj_after_lemmatization'] = df1.Text.apply(rem_stopwords).apply(lemma_spacy).apply(lambda x : \",\".join([a for a,b in TextBlob(x).pos_tags if b in ['JJ','JJR','JJS']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "colab_type": "code",
    "id": "3C9Tr8KgfbPl",
    "outputId": "e2add960-7279-456d-bb86-1d8a2090fc4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valet</td>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service</td>\n",
       "      <td>2301_1_Q1_2_2</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plus</td>\n",
       "      <td>2301_1_Q1_2_3</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thing</td>\n",
       "      <td>2301_2_Q1_1_1</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>[]</td>\n",
       "      <td>great,only,filled</td>\n",
       "      <td>slightly</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great,bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>water</td>\n",
       "      <td>2301_2_Q1_1_2</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>[]</td>\n",
       "      <td>great,only,filled</td>\n",
       "      <td>slightly</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great,bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>container</td>\n",
       "      <td>2301_2_Q1_1_3</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>[]</td>\n",
       "      <td>great,only,filled</td>\n",
       "      <td>slightly</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great,bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hall</td>\n",
       "      <td>2301_2_Q1_1_4</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>[]</td>\n",
       "      <td>great,only,filled</td>\n",
       "      <td>slightly</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great,bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elevator</td>\n",
       "      <td>2301_2_Q1_1_5</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>it was great the only thing that slightly bugg...</td>\n",
       "      <td>[]</td>\n",
       "      <td>great,only,filled</td>\n",
       "      <td>slightly</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great,bug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nouns             ID  \\\n",
       "0   location  2301_1_Q1_1_1   \n",
       "1      staff  2301_1_Q1_1_2   \n",
       "2      valet  2301_1_Q1_2_1   \n",
       "3    service  2301_1_Q1_2_2   \n",
       "4       plus  2301_1_Q1_2_3   \n",
       "5      thing  2301_2_Q1_1_1   \n",
       "6      water  2301_2_Q1_1_2   \n",
       "7  container  2301_2_Q1_1_3   \n",
       "8       hall  2301_2_Q1_1_4   \n",
       "9   elevator  2301_2_Q1_1_5   \n",
       "\n",
       "                                                Text  \\\n",
       "0           location and friendly professional staff   \n",
       "1           location and friendly professional staff   \n",
       "2                           valet service was a plus   \n",
       "3                           valet service was a plus   \n",
       "4                           valet service was a plus   \n",
       "5  it was great the only thing that slightly bugg...   \n",
       "6  it was great the only thing that slightly bugg...   \n",
       "7  it was great the only thing that slightly bugg...   \n",
       "8  it was great the only thing that slightly bugg...   \n",
       "9  it was great the only thing that slightly bugg...   \n",
       "\n",
       "                                             wn_sent Spacy_Entity  \\\n",
       "0           location and friendly professional staff           []   \n",
       "1           location and friendly professional staff           []   \n",
       "2                           valet service was a plus           []   \n",
       "3                           valet service was a plus           []   \n",
       "4                           valet service was a plus           []   \n",
       "5  it was great the only thing that slightly bugg...           []   \n",
       "6  it was great the only thing that slightly bugg...           []   \n",
       "7  it was great the only thing that slightly bugg...           []   \n",
       "8  it was great the only thing that slightly bugg...           []   \n",
       "9  it was great the only thing that slightly bugg...           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \\\n",
       "0  friendly,professional                   friendly,professional   \n",
       "1  friendly,professional                   friendly,professional   \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "5      great,only,filled         slightly                  great   \n",
       "6      great,only,filled         slightly                  great   \n",
       "7      great,only,filled         slightly                  great   \n",
       "8      great,only,filled         slightly                  great   \n",
       "9      great,only,filled         slightly                  great   \n",
       "\n",
       "  adj_after_stemming adj_after_lemmatization  \n",
       "0           friendli   friendly,professional  \n",
       "1           friendli   friendly,professional  \n",
       "2                                             \n",
       "3                                             \n",
       "4                                             \n",
       "5              great               great,bug  \n",
       "6              great               great,bug  \n",
       "7              great               great,bug  \n",
       "8              great               great,bug  \n",
       "9              great               great,bug  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l2 = 'I am Vasavi and I live in Bengaluru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[a for a,b in TextBlob(l2).pos_tags if b in [\"NN\", \"NNP\", \"NNS\", \"NNPS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = ['a','s','d']\n",
    "# a2 = ['w','e','s']\n",
    "# a3 = ['a','d','f','s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(a1) & set(a2) & set(a3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting +1/-1, +2/-2, +3/-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus1words(l1):\n",
    "\n",
    "    l1 = l1.split(\" \")\n",
    "\n",
    "    f = []\n",
    "\n",
    "    for i, e in enumerate(l1):\n",
    "\n",
    "        l = []\n",
    "\n",
    "        length = len(l1)\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            l.extend(l1[1:2])\n",
    "\n",
    "        \n",
    "        elif ((i > 0) & (i < (length - 1))):\n",
    "\n",
    "            l.extend(l1[i-1:i])\n",
    "            l.extend(l1[i+1:i+2])\n",
    "\n",
    "\n",
    "        elif i == (length - 1):\n",
    "\n",
    "            l.extend(l1[-2:-1])\n",
    "\n",
    "        # print(f\"Words surrounding  {e} are : {l}\")\n",
    "\n",
    "        a = (e,l)\n",
    "\n",
    "        f.append(a)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus1(Text, nouns):\n",
    "  for a,b in plus1words(Text):\n",
    "    if a == nouns:\n",
    "      return b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "      <th>1wordvicinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>[and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>[professional]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valet</td>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[, service]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nouns             ID                                      Text  \\\n",
       "0  location  2301_1_Q1_1_1  location and friendly professional staff   \n",
       "1     staff  2301_1_Q1_1_2  location and friendly professional staff   \n",
       "2     valet  2301_1_Q1_2_1                  valet service was a plus   \n",
       "\n",
       "                                    wn_sent Spacy_Entity  \\\n",
       "0  location and friendly professional staff           []   \n",
       "1  location and friendly professional staff           []   \n",
       "2                  valet service was a plus           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \\\n",
       "0  friendly,professional                   friendly,professional   \n",
       "1  friendly,professional                   friendly,professional   \n",
       "2                                                                  \n",
       "\n",
       "  adj_after_stemming adj_after_lemmatization   1wordvicinity  \n",
       "0           friendli   friendly,professional           [and]  \n",
       "1           friendli   friendly,professional  [professional]  \n",
       "2                                                [, service]  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"1wordvicinity\"] = df1.apply(lambda x: plus1(x['Text'], x['nouns']), axis = 1)\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus2words(l1):\n",
    "\n",
    "    l1 = l1.split(\" \")\n",
    "\n",
    "    f = []\n",
    "\n",
    "    for i, e in enumerate(l1):\n",
    "\n",
    "        l = []\n",
    "\n",
    "        length = len(l1)\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            l.extend(l1[1:3])\n",
    "\n",
    "        elif i == 1:\n",
    "\n",
    "            l.extend(l1[:1])\n",
    "\n",
    "            l.extend(l1[2:4])\n",
    "\n",
    "        elif (i > 1 & (i < length - 2)):\n",
    "\n",
    "            l.extend(l1[i-2:i])\n",
    "\n",
    "            l.extend(l1[i+1:i+3])\n",
    "\n",
    "        elif i == len(l1) - 2:\n",
    "\n",
    "            l.extend(l1[-4:-2])\n",
    "\n",
    "            l.extend(l1[-1])\n",
    "\n",
    "        elif i == len(l1) - 1:\n",
    "\n",
    "            l.extend(l1[-3:])\n",
    "\n",
    "        # print(f\"Words surrounding  {e} are : {l}\")\n",
    "\n",
    "        a = (e,l)\n",
    "\n",
    "        f.append(a)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus2(Text, nouns):\n",
    "  for a,b in plus2words(Text):\n",
    "    if a == nouns:\n",
    "      return b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "      <th>1wordvicinity</th>\n",
       "      <th>2wordvicinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>[and]</td>\n",
       "      <td>[and, friendly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>[professional]</td>\n",
       "      <td>[friendly, professional]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valet</td>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[, service]</td>\n",
       "      <td>[, service, was]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nouns             ID                                      Text  \\\n",
       "0  location  2301_1_Q1_1_1  location and friendly professional staff   \n",
       "1     staff  2301_1_Q1_1_2  location and friendly professional staff   \n",
       "2     valet  2301_1_Q1_2_1                  valet service was a plus   \n",
       "\n",
       "                                    wn_sent Spacy_Entity  \\\n",
       "0  location and friendly professional staff           []   \n",
       "1  location and friendly professional staff           []   \n",
       "2                  valet service was a plus           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \\\n",
       "0  friendly,professional                   friendly,professional   \n",
       "1  friendly,professional                   friendly,professional   \n",
       "2                                                                  \n",
       "\n",
       "  adj_after_stemming adj_after_lemmatization   1wordvicinity  \\\n",
       "0           friendli   friendly,professional           [and]   \n",
       "1           friendli   friendly,professional  [professional]   \n",
       "2                                                [, service]   \n",
       "\n",
       "              2wordvicinity  \n",
       "0           [and, friendly]  \n",
       "1  [friendly, professional]  \n",
       "2          [, service, was]  "
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"2wordvicinity\"] = df1.apply(lambda x: plus2(x['Text'], x['nouns']), axis = 1)\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus3words(l1):\n",
    "\n",
    "    l1 = l1.split(\" \")\n",
    "\n",
    "    f = []\n",
    "\n",
    "    for i, e in enumerate(l1):\n",
    "\n",
    "        l = []\n",
    "\n",
    "        length = len(l1)\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            l.extend(l1[1:4])\n",
    "\n",
    "        elif i == 1:\n",
    "\n",
    "            l.extend(l1[:1])\n",
    "\n",
    "            l.extend(l1[2:5])\n",
    "        elif i == 2:\n",
    "            l.extend(l1[:2])\n",
    "            l.extend(l1[3:6])\n",
    "\n",
    "        elif (i > 2 & (i < length - 3)):\n",
    "\n",
    "            l.extend(l1[i-3:i])\n",
    "\n",
    "            l.extend(l1[i+1:i+4])\n",
    "\n",
    "        elif i == len(l1) - 3:\n",
    "\n",
    "            l.extend(l1[-6:-3])\n",
    "\n",
    "            l.extend(l1[-2:])\n",
    "\n",
    "        elif i == len(l1) - 2:\n",
    "\n",
    "            l.extend(l1[-5:-2])\n",
    "\n",
    "            l.extend(l1[-1])\n",
    "\n",
    "        elif i == len(l1) - 1:\n",
    "\n",
    "            l.extend(l1[-4:])\n",
    "\n",
    "        # print(f\"Words surrounding  {e} are : {l}\")\n",
    "\n",
    "        a = (e,l)\n",
    "\n",
    "        f.append(a)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus3(Text, nouns):\n",
    "  for a,b in plus3words(Text):\n",
    "    if a == nouns:\n",
    "      return b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['noun_phrase'] = df1.apply(lambda x : list(TextBlob(str(x['Text'])).noun_phrases), axis = 1)\n",
    "df1['relavant_nounphrase'] = df1.apply(lambda x : [i for i in TextBlob(str(x['Text'])).noun_phrases if str(x['nouns']) in i], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "      <th>1wordvicinity</th>\n",
       "      <th>2wordvicinity</th>\n",
       "      <th>3wordvicinity</th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>relavant_nounphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>[and]</td>\n",
       "      <td>[and, friendly]</td>\n",
       "      <td>[and, friendly, professional]</td>\n",
       "      <td>[friendly professional staff]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>[professional]</td>\n",
       "      <td>[friendly, professional]</td>\n",
       "      <td>[and, friendly, professional]</td>\n",
       "      <td>[friendly professional staff]</td>\n",
       "      <td>[friendly professional staff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valet</td>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[, service]</td>\n",
       "      <td>[, service, was]</td>\n",
       "      <td>[, service, was, a]</td>\n",
       "      <td>[valet service]</td>\n",
       "      <td>[valet service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service</td>\n",
       "      <td>2301_1_Q1_2_2</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[valet, was]</td>\n",
       "      <td>[, valet, was, a]</td>\n",
       "      <td>[, valet, was, a, plus]</td>\n",
       "      <td>[valet service]</td>\n",
       "      <td>[valet service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plus</td>\n",
       "      <td>2301_1_Q1_2_3</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[a]</td>\n",
       "      <td>[was, a]</td>\n",
       "      <td>[service, was, a]</td>\n",
       "      <td>[valet service]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nouns             ID                                      Text  \\\n",
       "0  location  2301_1_Q1_1_1  location and friendly professional staff   \n",
       "1     staff  2301_1_Q1_1_2  location and friendly professional staff   \n",
       "2     valet  2301_1_Q1_2_1                  valet service was a plus   \n",
       "3   service  2301_1_Q1_2_2                  valet service was a plus   \n",
       "4      plus  2301_1_Q1_2_3                  valet service was a plus   \n",
       "\n",
       "                                    wn_sent Spacy_Entity  \\\n",
       "0  location and friendly professional staff           []   \n",
       "1  location and friendly professional staff           []   \n",
       "2                  valet service was a plus           []   \n",
       "3                  valet service was a plus           []   \n",
       "4                  valet service was a plus           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \\\n",
       "0  friendly,professional                   friendly,professional   \n",
       "1  friendly,professional                   friendly,professional   \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "\n",
       "  adj_after_stemming adj_after_lemmatization   1wordvicinity  \\\n",
       "0           friendli   friendly,professional           [and]   \n",
       "1           friendli   friendly,professional  [professional]   \n",
       "2                                                [, service]   \n",
       "3                                               [valet, was]   \n",
       "4                                                        [a]   \n",
       "\n",
       "              2wordvicinity                  3wordvicinity  \\\n",
       "0           [and, friendly]  [and, friendly, professional]   \n",
       "1  [friendly, professional]  [and, friendly, professional]   \n",
       "2          [, service, was]            [, service, was, a]   \n",
       "3         [, valet, was, a]        [, valet, was, a, plus]   \n",
       "4                  [was, a]              [service, was, a]   \n",
       "\n",
       "                     noun_phrase            relavant_nounphrase  \n",
       "0  [friendly professional staff]                             []  \n",
       "1  [friendly professional staff]  [friendly professional staff]  \n",
       "2                [valet service]                [valet service]  \n",
       "3                [valet service]                [valet service]  \n",
       "4                [valet service]                             []  "
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking common adjective from 1,2,3 word vicinity and noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.textblob_adjtags = df1.textblob_adjtags.map(str).apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"1wordvicinity\"] = df1[\"1wordvicinity\"].fillna(\" \")\n",
    "df1[\"1wordvicinity\"] = df1.apply(lambda x: list(set([i for i in x['textblob_adjtags'] if i in x['1wordvicinity']])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['1wordvicinity'] = df1['1wordvicinity'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"2wordvicinity\"] = df1[\"2wordvicinity\"].fillna(\" \")\n",
    "df1[\"2wordvicinity\"] = df1.apply(lambda x: list(set([i for i in x['textblob_adjtags'] if i in x['2wordvicinity']])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['2wordvicinity'] = df1['2wordvicinity'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"3wordvicinity\"] = df1[\"3wordvicinity\"].fillna(\" \")\n",
    "df1[\"3wordvicinity\"] = df1.apply(lambda x: list(set([i for i in x['textblob_adjtags'] if i in x['3wordvicinity']])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['3wordvicinity'] = df1['3wordvicinity'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['nounphrase_descriptor'] = df1.apply(lambda x: [i.replace(x['nouns'],\"\").strip() for i in x['relavant_nounphrase']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['relavant_nounphrase_list'] = df1.relavant_nounphrase.apply(lambda x: (\",\".join(x)).strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['textblob_adjtags'] = df1.textblob_adjtags.apply(lambda x: [i.strip() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['nounphrase_adj'] = df1.apply(lambda x: list(set([i for i in x['textblob_adjtags'] if i in x['relavant_nounphrase_list']])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['nounphrase_descriptor'] = df1['nounphrase_descriptor'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['nounphrase_adj'] = df1['nounphrase_adj'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['textblob_adjtags'] = df1['textblob_adjtags'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['noun_phrase'] = df1['noun_phrase'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['relavant_nounphrase'] = df1['relavant_nounphrase'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "      <th>1wordvicinity</th>\n",
       "      <th>2wordvicinity</th>\n",
       "      <th>3wordvicinity</th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>relavant_nounphrase</th>\n",
       "      <th>nounphrase_descriptor</th>\n",
       "      <th>relavant_nounphrase_list</th>\n",
       "      <th>nounphrase_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly</td>\n",
       "      <td>professional,friendly</td>\n",
       "      <td>friendly professional staff</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>professional</td>\n",
       "      <td>professional,friendly</td>\n",
       "      <td>professional,friendly</td>\n",
       "      <td>friendly professional staff</td>\n",
       "      <td>friendly professional staff</td>\n",
       "      <td>friendly professional</td>\n",
       "      <td>[friendly, professional, staff]</td>\n",
       "      <td>professional,friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valet</td>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>valet service</td>\n",
       "      <td>valet service</td>\n",
       "      <td>service</td>\n",
       "      <td>[valet, service]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service</td>\n",
       "      <td>2301_1_Q1_2_2</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>valet service</td>\n",
       "      <td>valet service</td>\n",
       "      <td>valet</td>\n",
       "      <td>[valet, service]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plus</td>\n",
       "      <td>2301_1_Q1_2_3</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>valet service</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nouns             ID                                      Text  \\\n",
       "0  location  2301_1_Q1_1_1  location and friendly professional staff   \n",
       "1     staff  2301_1_Q1_1_2  location and friendly professional staff   \n",
       "2     valet  2301_1_Q1_2_1                  valet service was a plus   \n",
       "3   service  2301_1_Q1_2_2                  valet service was a plus   \n",
       "4      plus  2301_1_Q1_2_3                  valet service was a plus   \n",
       "\n",
       "                                    wn_sent Spacy_Entity  \\\n",
       "0  location and friendly professional staff           []   \n",
       "1  location and friendly professional staff           []   \n",
       "2                  valet service was a plus           []   \n",
       "3                  valet service was a plus           []   \n",
       "4                  valet service was a plus           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \\\n",
       "0  friendly,professional                   friendly,professional   \n",
       "1  friendly,professional                   friendly,professional   \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "\n",
       "  adj_after_stemming adj_after_lemmatization 1wordvicinity  \\\n",
       "0           friendli   friendly,professional                 \n",
       "1           friendli   friendly,professional  professional   \n",
       "2                                                            \n",
       "3                                                            \n",
       "4                                                            \n",
       "\n",
       "           2wordvicinity          3wordvicinity                  noun_phrase  \\\n",
       "0               friendly  professional,friendly  friendly professional staff   \n",
       "1  professional,friendly  professional,friendly  friendly professional staff   \n",
       "2                                                              valet service   \n",
       "3                                                              valet service   \n",
       "4                                                              valet service   \n",
       "\n",
       "           relavant_nounphrase  nounphrase_descriptor  \\\n",
       "0                                                       \n",
       "1  friendly professional staff  friendly professional   \n",
       "2                valet service                service   \n",
       "3                valet service                  valet   \n",
       "4                                                       \n",
       "\n",
       "          relavant_nounphrase_list         nounphrase_adj  \n",
       "0                               []                         \n",
       "1  [friendly, professional, staff]  professional,friendly  \n",
       "2                 [valet, service]                         \n",
       "3                 [valet, service]                         \n",
       "4                               []                         "
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nouns', 'ID', 'Text', 'wn_sent', 'Spacy_Entity', 'textblob_adjtags',\n",
       "       'textblob_advtags', 'adjtags_removedSW', 'adj_after_stemming',\n",
       "       'adj_after_lemmatization', '1wordvicinity', '2wordvicinity',\n",
       "       '3wordvicinity', 'noun_phrase', 'relavant_nounphrase',\n",
       "       'nounphrase_descriptor', 'relavant_nounphrase_list', 'nounphrase_adj'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reindex(columns = ['ID', 'Text', 'nouns', 'wn_sent', 'Spacy_Entity', 'textblob_adjtags',\n",
    "       'textblob_advtags', 'adjtags_removedSW', 'adj_after_stemming',\n",
    "       'adj_after_lemmatization', '1wordvicinity', '2wordvicinity',\n",
    "       '3wordvicinity', 'noun_phrase', 'relavant_nounphrase',\n",
    "       'nounphrase_descriptor' , 'nounphrase_adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>nouns</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "      <th>1wordvicinity</th>\n",
       "      <th>2wordvicinity</th>\n",
       "      <th>3wordvicinity</th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>relavant_nounphrase</th>\n",
       "      <th>nounphrase_descriptor</th>\n",
       "      <th>nounphrase_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>17504_552_Q2_1_1</td>\n",
       "      <td>we arrived at 430 pm and didnt get a room unti...</td>\n",
       "      <td>pm</td>\n",
       "      <td>we arrived at 430 pm and didnt get a room unti...</td>\n",
       "      <td>[(430 pm, TIME), (8pm, TIME)]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nt</td>\n",
       "      <td></td>\n",
       "      <td>arrive,nt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21577</th>\n",
       "      <td>17504_634_Q2_1_1</td>\n",
       "      <td>would have had our room cleaned by 300 pm</td>\n",
       "      <td>room</td>\n",
       "      <td>would have had our room cleaned by 300 pm</td>\n",
       "      <td>[(300 pm, TIME)]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>2301_526_Q1_2_1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>2301_447_Q1_1_9</td>\n",
       "      <td>concierge, front desk staff, decor, location, ...</td>\n",
       "      <td>cottage</td>\n",
       "      <td>concierge front desk staff decor location all ...</td>\n",
       "      <td>[(decor, ORG), (5, CARDINAL)]</td>\n",
       "      <td>front,top,small,modern,large,upscale</td>\n",
       "      <td></td>\n",
       "      <td>desk,small,modern,large,upscale</td>\n",
       "      <td>front,top,small,modern,upscal</td>\n",
       "      <td>desk,small,modern,large,upscale</td>\n",
       "      <td>modern</td>\n",
       "      <td>small,modern</td>\n",
       "      <td>small,modern</td>\n",
       "      <td>front desk staff,star top notch i,small modern...</td>\n",
       "      <td>small modern cottage</td>\n",
       "      <td>small modern</td>\n",
       "      <td>small,modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>2301_806_Q1_1_1</td>\n",
       "      <td>i enjoyed being close to the action but also n...</td>\n",
       "      <td>i</td>\n",
       "      <td>i enjoyed being close to the action but also n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>close,able</td>\n",
       "      <td>also,not</td>\n",
       "      <td>close,able,hear</td>\n",
       "      <td>close,hear,anyth</td>\n",
       "      <td>close,able,hear</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>close</td>\n",
       "      <td>hotel room</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>17504_311_Q1_2_1</td>\n",
       "      <td>loved the well dressed and well spoken guy b...</td>\n",
       "      <td>well</td>\n",
       "      <td>loved the well dressed and well spoken guy beh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>checkin</td>\n",
       "      <td>well</td>\n",
       "      <td>dressed,spoken,checkin</td>\n",
       "      <td>spoken,checkin</td>\n",
       "      <td>spoken,checkin</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>checkin area</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9262</th>\n",
       "      <td>17504_894_Q1_2_1</td>\n",
       "      <td>the shuttle service is excellent, the drivers...</td>\n",
       "      <td>service</td>\n",
       "      <td>the shuttle service is excellent the drivers w...</td>\n",
       "      <td>[]</td>\n",
       "      <td>shuttle,excellent,excellent</td>\n",
       "      <td></td>\n",
       "      <td>shuttle</td>\n",
       "      <td>servic</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle service</td>\n",
       "      <td>shuttle service</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9477</th>\n",
       "      <td>17504_941_Q1_2_1</td>\n",
       "      <td>overall a great experience</td>\n",
       "      <td>experience</td>\n",
       "      <td>overall a great experience</td>\n",
       "      <td>[]</td>\n",
       "      <td>overall,great</td>\n",
       "      <td></td>\n",
       "      <td>overall,great</td>\n",
       "      <td>overal,great</td>\n",
       "      <td>overall,great</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great,overall</td>\n",
       "      <td>great experience</td>\n",
       "      <td>great experience</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16931</th>\n",
       "      <td>17504_19_Q2_1_2</td>\n",
       "      <td>better tv channels, microwave in the room</td>\n",
       "      <td>channels</td>\n",
       "      <td>better tv channels microwave in the room</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>better</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>tv channels</td>\n",
       "      <td>tv channels</td>\n",
       "      <td>tv</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24173</th>\n",
       "      <td>17504_1069_Q2_11_1</td>\n",
       "      <td>really great service</td>\n",
       "      <td>service</td>\n",
       "      <td>really great service</td>\n",
       "      <td>[]</td>\n",
       "      <td>great</td>\n",
       "      <td>really</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>great service</td>\n",
       "      <td>great service</td>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                               Text  \\\n",
       "20998    17504_552_Q2_1_1  we arrived at 430 pm and didnt get a room unti...   \n",
       "21577    17504_634_Q2_1_1          would have had our room cleaned by 300 pm   \n",
       "2358      2301_526_Q1_2_1                                                      \n",
       "2029      2301_447_Q1_1_9  concierge, front desk staff, decor, location, ...   \n",
       "3511      2301_806_Q1_1_1  i enjoyed being close to the action but also n...   \n",
       "6532     17504_311_Q1_2_1    loved the well dressed and well spoken guy b...   \n",
       "9262     17504_894_Q1_2_1   the shuttle service is excellent, the drivers...   \n",
       "9477     17504_941_Q1_2_1                         overall a great experience   \n",
       "16931     17504_19_Q2_1_2          better tv channels, microwave in the room   \n",
       "24173  17504_1069_Q2_11_1                               really great service   \n",
       "\n",
       "            nouns                                            wn_sent  \\\n",
       "20998          pm  we arrived at 430 pm and didnt get a room unti...   \n",
       "21577        room          would have had our room cleaned by 300 pm   \n",
       "2358                                                                   \n",
       "2029      cottage  concierge front desk staff decor location all ...   \n",
       "3511            i  i enjoyed being close to the action but also n...   \n",
       "6532         well  loved the well dressed and well spoken guy beh...   \n",
       "9262      service  the shuttle service is excellent the drivers w...   \n",
       "9477   experience                         overall a great experience   \n",
       "16931    channels           better tv channels microwave in the room   \n",
       "24173     service                               really great service   \n",
       "\n",
       "                        Spacy_Entity                      textblob_adjtags  \\\n",
       "20998  [(430 pm, TIME), (8pm, TIME)]                                         \n",
       "21577               [(300 pm, TIME)]                                         \n",
       "2358                              []                                         \n",
       "2029   [(decor, ORG), (5, CARDINAL)]  front,top,small,modern,large,upscale   \n",
       "3511                              []                            close,able   \n",
       "6532                              []                               checkin   \n",
       "9262                              []           shuttle,excellent,excellent   \n",
       "9477                              []                         overall,great   \n",
       "16931                             []                                         \n",
       "24173                             []                                 great   \n",
       "\n",
       "      textblob_advtags                adjtags_removedSW  \\\n",
       "20998                                                nt   \n",
       "21577                                                     \n",
       "2358                                                      \n",
       "2029                    desk,small,modern,large,upscale   \n",
       "3511          also,not                  close,able,hear   \n",
       "6532              well           dressed,spoken,checkin   \n",
       "9262                                            shuttle   \n",
       "9477                                      overall,great   \n",
       "16931           better                                    \n",
       "24173           really                            great   \n",
       "\n",
       "                  adj_after_stemming          adj_after_lemmatization  \\\n",
       "20998                                                       arrive,nt   \n",
       "21577                                                                   \n",
       "2358                                                                    \n",
       "2029   front,top,small,modern,upscal  desk,small,modern,large,upscale   \n",
       "3511                close,hear,anyth                  close,able,hear   \n",
       "6532                  spoken,checkin                   spoken,checkin   \n",
       "9262                          servic                          shuttle   \n",
       "9477                    overal,great                    overall,great   \n",
       "16931                                                                   \n",
       "24173                          great                            great   \n",
       "\n",
       "      1wordvicinity 2wordvicinity  3wordvicinity  \\\n",
       "20998                                              \n",
       "21577                                              \n",
       "2358                                               \n",
       "2029         modern  small,modern   small,modern   \n",
       "3511                                       close   \n",
       "6532                                               \n",
       "9262        shuttle       shuttle        shuttle   \n",
       "9477          great         great  great,overall   \n",
       "16931                                              \n",
       "24173         great         great          great   \n",
       "\n",
       "                                             noun_phrase  \\\n",
       "20998                                                      \n",
       "21577                                                      \n",
       "2358                                                       \n",
       "2029   front desk staff,star top notch i,small modern...   \n",
       "3511                                          hotel room   \n",
       "6532                                        checkin area   \n",
       "9262                                     shuttle service   \n",
       "9477                                    great experience   \n",
       "16931                                        tv channels   \n",
       "24173                                      great service   \n",
       "\n",
       "        relavant_nounphrase nounphrase_descriptor nounphrase_adj  \n",
       "20998                                                             \n",
       "21577                                                             \n",
       "2358                                                              \n",
       "2029   small modern cottage          small modern   small,modern  \n",
       "3511                                                              \n",
       "6532                                                              \n",
       "9262        shuttle service               shuttle        shuttle  \n",
       "9477       great experience                 great          great  \n",
       "16931           tv channels                    tv                 \n",
       "24173         great service                 great          great  "
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################Filtering Using IHG List########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = pd.read_excel(r\"C:\\Users\\u326421\\Desktop\\IHG - Text\\Entity List.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict[\"Entity\"] = dict[\"Entity\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list = list(dict[\"Entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"matched_words\"] = df1[\"nouns\"].apply(lambda x: list(x for x in x.split() if x in ent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"IHG_List_Matching\"] = df1.nouns.apply(lambda x: \"Yes\" if x in ent_list else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         \n",
       "1         \n",
       "2         \n",
       "3         \n",
       "4         \n",
       "        ..\n",
       "24775     \n",
       "24776     \n",
       "24777     \n",
       "24778     \n",
       "24779     \n",
       "Length: 24780, dtype: object"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Detecting Not and No from the sentence\n",
    "df1.apply(lambda x: \",\".join([i.strip() for i in x['Text'].split() if i in ['not','no']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of not words\n",
    "w1 = df1['adjtags_removedSW'].map(str).apply(lambda x : x.split(\",\")).apply(pd.Series).stack().reset_index(name = 'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-be6512933484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'no'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'not'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"couldn't\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"shouldn't\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w1' is not defined"
     ]
    }
   ],
   "source": [
    "w1['new'] = w1.word.apply(lambda x: 'no' + str(x))\n",
    "w1['new1'] = w1.word.apply(lambda x: 'not' + str(x))\n",
    "w1['new2'] = w1.word.apply(lambda x: \"couldn't\" + str(x))\n",
    "w1['new3'] = w1.word.apply(lambda x: \"shouldn't\" + str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words = pd.concat([w1.new,w1.new1,w1.new2,w1.new3], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "# the list containing the pharses to be matched\n",
    "terminology_list = desc_words\n",
    "# convert the phrases into document object using nlp.make_doc to #speed up.\n",
    "patterns = [nlp.make_doc(text) for text in terminology_list]\n",
    "# add the patterns to the matcher object without any callbacks\n",
    "matcher.add(\"Phrase Matching\", None, *patterns)\n",
    "# the input text string is converted to a Document object\n",
    "\n",
    "def match_phrase(text):\n",
    "  doc = nlp(text)\n",
    "  #call the matcher object the document object and it will return #match_id, start and stop indexes of the matched words\n",
    "  matches = matcher(doc)\n",
    "  #print the matched results and extract out the results\n",
    "  l1 = []\n",
    "  for match_id, start, end in matches:\n",
    "      # Get the string representation \n",
    "      string_id = nlp.vocab.strings[match_id]  \n",
    "      span = doc[start:end]  # The matched span\n",
    "      #print(match_id, string_id, start, end, span.text)\n",
    "      l1.append(span.text)\n",
    "  return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Not_No_Words\"] = df1.Text.apply(lambda x: match_phrase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Not_No_Words'] = df1['Not_No_Words'].apply(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Sentiment Scores - VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Vader Sentiment Scores\n",
    "df1[\"Vader_Positive\"] = df1[\"Text\"].map(str).apply(lambda x: analyser.polarity_scores(x)['pos'])\n",
    "df1[\"Vader_Negative\"] = df1[\"Text\"].map(str).apply(lambda x: analyser.polarity_scores(x)['neg'])\n",
    "df1[\"Vader_Neutral\"] = df1[\"Text\"].map(str).apply(lambda x: analyser.polarity_scores(x)['neu'])\n",
    "df1[\"Vader_Compound\"] = df1[\"Text\"].map(str).apply(lambda x: analyser.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimenttags(x):\n",
    "    if x > 0.00 : \n",
    "        return(\"Positive\") \n",
    "  \n",
    "    elif x < 0.00 : \n",
    "        return(\"Negative\") \n",
    "  \n",
    "    else : \n",
    "        return(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Sentiment_Tags\"] = df1.Vader_Compound.apply(lambda x: sentimenttags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>nouns</th>\n",
       "      <th>wn_sent</th>\n",
       "      <th>Spacy_Entity</th>\n",
       "      <th>textblob_adjtags</th>\n",
       "      <th>textblob_advtags</th>\n",
       "      <th>adjtags_removedSW</th>\n",
       "      <th>adj_after_stemming</th>\n",
       "      <th>adj_after_lemmatization</th>\n",
       "      <th>...</th>\n",
       "      <th>nounphrase_descriptor</th>\n",
       "      <th>nounphrase_adj</th>\n",
       "      <th>matched_words</th>\n",
       "      <th>IHG_List_Matching</th>\n",
       "      <th>Not_No_Words</th>\n",
       "      <th>Vader_Positive</th>\n",
       "      <th>Vader_Negative</th>\n",
       "      <th>Vader_Neutral</th>\n",
       "      <th>Vader_Compound</th>\n",
       "      <th>Sentiment_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301_1_Q1_1_1</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>location</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[location]</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2301_1_Q1_1_2</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>location and friendly professional staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td></td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friendly,professional</td>\n",
       "      <td>...</td>\n",
       "      <td>friendly professional</td>\n",
       "      <td>professional,friendly</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301_1_Q1_2_1</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>valet</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>service</td>\n",
       "      <td></td>\n",
       "      <td>[valet]</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2301_1_Q1_2_2</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>service</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>valet</td>\n",
       "      <td></td>\n",
       "      <td>[service]</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2301_1_Q1_2_3</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>plus</td>\n",
       "      <td>valet service was a plus</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                      Text     nouns  \\\n",
       "0  2301_1_Q1_1_1  location and friendly professional staff  location   \n",
       "1  2301_1_Q1_1_2  location and friendly professional staff     staff   \n",
       "2  2301_1_Q1_2_1                  valet service was a plus     valet   \n",
       "3  2301_1_Q1_2_2                  valet service was a plus   service   \n",
       "4  2301_1_Q1_2_3                  valet service was a plus      plus   \n",
       "\n",
       "                                    wn_sent Spacy_Entity  \\\n",
       "0  location and friendly professional staff           []   \n",
       "1  location and friendly professional staff           []   \n",
       "2                  valet service was a plus           []   \n",
       "3                  valet service was a plus           []   \n",
       "4                  valet service was a plus           []   \n",
       "\n",
       "        textblob_adjtags textblob_advtags      adjtags_removedSW  \\\n",
       "0  friendly,professional                   friendly,professional   \n",
       "1  friendly,professional                   friendly,professional   \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "\n",
       "  adj_after_stemming adj_after_lemmatization  ...  nounphrase_descriptor  \\\n",
       "0           friendli   friendly,professional  ...                          \n",
       "1           friendli   friendly,professional  ...  friendly professional   \n",
       "2                                             ...                service   \n",
       "3                                             ...                  valet   \n",
       "4                                             ...                          \n",
       "\n",
       "          nounphrase_adj matched_words IHG_List_Matching Not_No_Words  \\\n",
       "0                           [location]               Yes                \n",
       "1  professional,friendly       [staff]               Yes                \n",
       "2                              [valet]               Yes                \n",
       "3                            [service]               Yes                \n",
       "4                                   []                No                \n",
       "\n",
       "  Vader_Positive Vader_Negative Vader_Neutral Vader_Compound Sentiment_Tags  \n",
       "0          0.444            0.0         0.556         0.4939       Positive  \n",
       "1          0.444            0.0         0.556         0.4939       Positive  \n",
       "2          0.000            0.0         1.000         0.0000        Neutral  \n",
       "3          0.000            0.0         1.000         0.0000        Neutral  \n",
       "4          0.000            0.0         1.000         0.0000        Neutral  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding unique adjectives from multiple columns\n",
    "dd1['common'] = dd1['textblob_adjtags'].fillna(\" \") + \",\" + dd1['adjtags_removedSW'].fillna(\" \") + \",\" + dd1['adj_after_stemming'].fillna(\" \") + \",\" + dd1['adj_after_lemmatization'].fillna(\" \") + \",\" + dd1['1wordvicinity'].fillna(\" \")\\\n",
    " + \",\" + dd1['2wordvicinity'].fillna(\" \") + \",\" + dd1['3wordvicinity'].fillna(\" \")\n",
    "\n",
    "dd1['common'] = dd1['common'].apply(lambda x: list(set(x.split(\",\"))))\n",
    "dd1['common'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Creating 2 or more word entities from noun-phrases#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1['common1'] = dd1['common'].map(str)\n",
    "t1 = dd1[['ID','noun_phrase','common1']].set_index(['ID','common1']).noun_phrase.apply(lambda x: str(x).split(\",\")).apply(pd.Series).stack().reset_index(name = 'np')\n",
    "t1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.common1 = t1.common1.apply(lambda x: x.replace(\"[\",\"\")).\\\n",
    "apply(lambda x: x.replace(\"]\",\"\")).\\\n",
    "apply(lambda x: x.replace(\"'\",\"\")).apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.common1 = t1.common1.apply(lambda x: [i.strip() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1['np_entity'] = t1.apply(lambda x: \" \".join([i for i in x['np'].split(\" \") if i not in x['common1']]), axis = 1)\n",
    "t2 = t1.groupby('ID').np_entity.apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.np_entity = t2.np_entity.apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1 = dd1.merge(t2, left_on = \"ID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################Getting final descriptor from multiple columns##########################\n",
    "\n",
    "for i in range(dd1.shape[0]):\n",
    "    \n",
    "    if (~(dd1['1wordvicinity'].isna().values[i])):\n",
    "        dd1.loc[i,'new_col'] = dd1['1wordvicinity'][i]\n",
    "        \n",
    "    elif ~(dd1['2wordvicinity'].isna().values[i]):\n",
    "        dd1.loc[i,'new_col'] = dd1['2wordvicinity'][i]\n",
    "        \n",
    "    elif ~(df1['3wordvicinity'].isna().values[i]):\n",
    "        dd1.loc[i,'new_col'] = dd1['3wordvicinity'][i]\n",
    "        \n",
    "    elif ~(dd1['nounphrase_adj'].isna().values[i]):\n",
    "        dd1.loc[i,'new_col'] = dd1['nounphrase_adj'][i]\n",
    "        \n",
    "    elif ~(dd1['textblob_adjtags'].isna().values[i]):\n",
    "        dd1.loc[i,'new_col'] = dd1['textblob_adjtags'][i]\n",
    "        \n",
    "    else:\n",
    "        dd1.loc[i,'new_col'] = 'No Descriptor Found'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dd1[['ID', 'Entity', 'np_entity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.ID = dd.ID.apply(lambda x: x[0:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dd.set_index('ID').stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_excel(r\"C:\\Users\\u326421\\Desktop\\IHG - Text\\IHG_Output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IHG_18Feb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
